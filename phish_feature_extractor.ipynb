{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eefabb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "#import numpy as np\n",
    "\n",
    "import rf_model\n",
    "#import phish_feature_extractor\n",
    "\n",
    "\n",
    "class feature_extractor:\n",
    "        def __init__(self,url:str):\n",
    "\n",
    "            self.input_url = url\n",
    "    \n",
    "        def long_url(self,l):\n",
    "            \"\"\"This function is defined in order to differntiate website based on the length of the URL\"\"\"\n",
    "            l= str(l)\n",
    "            if len(l) < 54:\n",
    "                return 0\n",
    "            elif len(l) >= 54 and len(l) <= 75:\n",
    "                return 2\n",
    "            return 1\n",
    "    \n",
    "        def have_at_symbol(self,l):\n",
    "            \"\"\"This function is used to check whether the URL contains @ symbol or not\"\"\"\n",
    "            if \"@\" in str(l):\n",
    "                return 1\n",
    "            return 0\n",
    "    \n",
    "        def redirection(self,l):\n",
    "            \"\"\"If the url has symbol(//) after protocol then such URL is to be classified as phishing \"\"\"\n",
    "            if \"//\" in str(l):\n",
    "                return 1\n",
    "            return 0\n",
    "    \n",
    "        def prefix_suffix_seperation(self,l):\n",
    "            \"\"\"seprate prefix and suffix\"\"\"\n",
    "            if '-' in str(l):\n",
    "                return 1\n",
    "            return 0\n",
    "    \n",
    "        def sub_domains(self,l):\n",
    "            \"\"\"check the subdomains\"\"\"\n",
    "            l= str(l)\n",
    "            if l.count('.') < 3:\n",
    "                return 0\n",
    "            elif l.count('.') == 3:\n",
    "                return 2\n",
    "            return 1\n",
    "    \n",
    "    \n",
    "        def extract(self):\n",
    "            try:\n",
    "                \n",
    "                print(\"in script 2\")\n",
    "                input_data = [{\"URL\":self.input_url}]\n",
    "                print('input taken')\n",
    "                temp_df = pd.DataFrame(input_data)\n",
    "                print(\"dataframe created\")\n",
    "                #expand argument in the split method will give you a new column\n",
    "                seperation_of_protocol = temp_df['URL'].str.split(\"://\",expand = True)\n",
    "                print(\"step 1 done\")\n",
    "                #split(seperator,no of splits according to seperator(delimiter),expand)\n",
    "                seperation_domain_name = seperation_of_protocol[1].str.split(\"/\",1,expand = True)\n",
    "                print(\"step 2 done\")\n",
    "                #renaming columns of data frame\n",
    "                seperation_domain_name.columns=[\"domain_name\",\"address\"]\n",
    "                print(\"step 3 done\")\n",
    "                #Concatenation of data frames\n",
    "                splitted_data = pd.concat([seperation_of_protocol[0],seperation_domain_name],axis=1)\n",
    "                print(\"step 4 done\")\n",
    "        \n",
    "                splitted_data.columns = ['protocol','domain_name','address']\n",
    "                print(\"step 5 done\")\n",
    "        \n",
    "                #splitted_data['is_phished'] = pd.Series(temp_df['Target'], index=splitted_data.index)\n",
    "                #print(\"step 6 done\")\n",
    "        \n",
    "                \"\"\"feature extraction starts here\"\"\"\n",
    "                #Applying the above defined function in order to divide the websites into 3 categories\n",
    "                splitted_data['long_url'] = temp_df['URL'].apply(self.long_url)\n",
    "                print(\"feature extra 1\")\n",
    "                splitted_data['having_@_symbol'] = temp_df['URL'].apply(self.have_at_symbol)\n",
    "                print(\"feature extra 2\")\n",
    "                splitted_data['redirection_//_symbol'] = seperation_of_protocol[1].apply(self.redirection)\n",
    "                print(\"feature extra 3\")\n",
    "                splitted_data['prefix_suffix_seperation'] = seperation_domain_name['domain_name'].apply(self.prefix_suffix_seperation)\n",
    "                print(\"feature extra 4\")\n",
    "                splitted_data['sub_domains'] = splitted_data['domain_name'].apply(self.sub_domains)\n",
    "                print(\"feature extra 5\")\n",
    "                #splitted_data.to_csv(r'dataset3.csv',header= True)\n",
    "        \n",
    "                \n",
    "        \n",
    "                return rf_model.predictor(splitted_data)\n",
    "            except:\n",
    "                return (\"Please enter Correct URL in the format (http:// or https://)\")\n",
    "\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "    \n",
    "#    url = \"https://www.amazon.in/ref=as_li_ss_tl?ie=UTF8&linkCode=ll2&tag=enin-edge-topsites-curate-ana-21&linkId=fbedcb44d04a4bae8eae32722a2f41c2&language=en_IN\"\n",
    "    \n",
    "#    phish_obj = phish_feature_extractor.feature_extractor(url)\n",
    "#    phish_str = phish_obj.extract()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709c51df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
